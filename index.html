html:
        <!DOCTYPE html>
           <html lang="en">
            <head>
                <meta charset="UTF-8">
                <meta http-equiv="X-UA-Compatible" content="IE=edge">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <title>The Life of Kate Roney</title>
            </head>
            <body>
            <h1 id="hello" class="section-heading">Hello Fellow Bloggers and Viewers</h1>
            
            <p><img src="Screen Shot 2021-10-14 at 10.32 1.png" alt="Some Memorable Moments"> </p>
            <h2 id="hello-features">Here is a boring paper I had to write today. I got a 93% though :) Also I attached some code I also had to write!! Hope you enjoy!! Regarding the problem of AI detecting uploaded files by users, we will get two different results from the utilitarian and deontological perspectives. I will present my views on these two cases below.
                First, from the perspective of utilitarianism. The main idea of utilitarianism is to maximize the happiness value of the result. In order to make the overall network environment healthier, inspections are necessary, and among netizens, underage users account for a large proportion. The company's approach is not a problem. From the perspective of utilitarianism, everything is valuable and can be calculated, just like in Trolley Problem, the utilitarian will pull down the lever to save five people at the cost of killing one person, even if from a legal and humanitarian perspective, life is priceless and cannot be compared by quantity. Therefore, in the ai problem, even if the inspection process violated the company's own promise of "cannot read encrypted files". Because from an objective point of view, most of the files uploaded by users are legal and do not involve pornographic information. So, such an inspection will be in the interests of most people.
                Second, from the point of view of deontology, the company's approach is undoubtedly wrong, and in many ways, it violates the deontology. First, the company violated its promise to "not read encrypted files." In deontology, fulfilling promises is one of the codes of conduct, so from this point of view alone, the company's approach is already wrong. Secondly, viewing the user's encrypted files violates morality and infringes on the user's personal privacy. Even if it is to protect the interests of most people, it cannot be at the cost of giving up the interests of a small group of people. Finally, the reason why the company chose to use ai to check the illegal images is undoubtedly to delete them after finding out, or to warn users. This undoubtedly violates the golden rule in the theory of deontology, and from the perspective of the golden rule, even if the company does not promise that it will never infringe the user’s personal privacy, it cannot use ai to detect the user’s files, let alone delete the user’s files. Even if he violated the rules. Because there is a very important theory in the Golden Rule to treat others the way you want them to treat you. Personally, no one wants to delete or view their encrypted uploads. Therefore, the moment the company is elected to use ai to check the documents, it has violated the theory of deontology.
                In summary, there is no absolute right or wrong between these two theories. What matters is the position of the parties. Whether your so-called privacy undermines the interests of others, and whether your interests can only be achieved from the standpoint of talking about the privacy of others. Assuming that more than half of the users who use this company's cloud storage have uploaded files that do not meet the requirements or only some parents have uploaded photos of naked babies, then the above two situations have become different again. Utilitarianism will no longer apply to the company, because no matter what it does, the company destroys the interests of most people.
                In fact, I think whether the company should check the user's encrypted files is like a modern Trolley Problem. In an ideal state, a network system with no illegal files is like five people tied to one railroad track, and the privacy of users who upload illegal files is like someone tied to another railroad track. We can only choose to protect the interests of one side or hurt the interests of one side. On the surface, the problem we are facing is to use ai to check user files, but in reality it is correct to judge whether it is correct to violate the rules set by oneself and destroy the interests of a small group of people to save the interests of the general public. From an ethical point of view, both parties have their own reasons. But as far as I am concerned, I cannot fully support any of them. Just like Trolley Problem itself was proposed by Philippa Foot to criticize utilitarianism and deontology. In fact, the main ideas of these two theories are exactly where the other party is inadequate. Utilitarianism emphasizes results, while deontology focuses on whether the process of behavior conforms to moral standards. The ai problem in the article can also have a better solution in real life. For example, in the process of storing files, the company can obey its own rules that encrypted files are unreadable and abide by the deontology to ensure that the personal privacy of all users is not violated.  However, in the path of reading or transmitting files to other users, the company can use ai to check, and then hand over to the staff to judge whether the file can be read. Combining the two theories will get better results.
                In general, the processing methods are naturally different depending on the event. For example, in the ward, there are ten patients in urgent need of organ transplantation, and the organs they need are different. In the absence of any organ storage, is it correct to kill one patient in exchange for the survival of nine others? In this case, utilitarianism is obviously incorrect, because we are humans, not machines, and we need to consider more than 9 greater than 1. However, in the 1990s, China unconditionally forced a lot of workers to be laid off, but this also saved the domestic economy. Although for those workers, this is unethical, but for the entire country’s economic recovery and future development. it's necessary. Or in a bomb disposal mission, if a hostage is loaded with a bomb that can hardly be dismantled, is it still necessary to rule out bomb disposal experts to perform an almost mortal mission? I don’t think that officer will give an order to dismantle the bomb, even if we have to risk saving the hostages on the basis of deontology. From a different perspective, status, and considerations are also completely different. How to balance various theories and use them correctly in life is what we need to learn.
                
            </p>

            
            <p><a href="https://en.wikipedia.org/wiki/HAL_9000">HAL 9000</a></p>
            
            </body>
            </html>